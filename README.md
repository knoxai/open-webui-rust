# Open WebUI with Rust Backend ÔΩú [ÁÆÄ‰Ωì‰∏≠Êñá](./README.zh-CN.md)

High‚ÄëPerformance Rust Implementation of Open‚ÄØWebUI

## Docker Quick Start

```
git clone https://github.com/knoxchat/open-webui-rust.git && cd open-webui-rust
docker compose up -d
```
> Ensure Docker and Docker Compose are ready

https://github.com/user-attachments/assets/d1bf00a3-1838-4658-84da-d8bfc84a9ec3

## Overview

The Rust backend is a drop-in replacement for the Python backend, offering:

- **10-50x faster response times** for API endpoints
- **70% lower memory usage** under load
- **Native concurrency** with Tokio's async runtime
- **Type safety** preventing entire classes of runtime errors
- **Zero-copy streaming** for chat completions
- **Production-ready** with comprehensive error handling

## **IMPORTANT‚ÄºÔ∏è** Rust Backend Current Complete Code Status: 85% (Runnable Project, Some Features Missing)

- **Initial Version Based on Open WebUI 0.6.32** The development of this project's initial version updates files according to sponsorship amounts. Backend files are added based on donations/sponsorships until the complete backend files are added:

   - **Target: $10,000 or Sufficient Star Count to Add Complete Backend Code**

   1. Sponsorship of $20-$99: Update 2 files, add sponsor to project contributors list, e.g.: John Doe-$66
   2. Each Star: Add 5 files
   3. Sponsorship of $100-$500: Update 6 files, add sponsor to project contributors list with designated link, e.g.: [Jane Doe-$180](https://Jane-Doe.domain)
   4. Sponsorship of $501-$2000: Update 10 files, add sponsor to project contributors list with designated link and image, e.g.: <br/>
   <a href="https://knox.chat" target="_blank" rel="noopener noreferrer">
    <img width="80" src="./img/logo99.png" alt="Name">
   </a><br/>
   5. Sponsorship of $10,000: Directly update all files and list as project partner, add sponsor to project contributors list with designated link and image, and provide usage and deployment support.

- **For Sponsorships: Please Scan the QR Code Below via Alipay or Paypal to Sponsor and Contact: support@knox.chat**

<p align="center" style="display: flex; align-items: center; justify-content: center; gap: 20px;">
   <img width="246" src="./img/ali.png" alt="Name">
   <img width="229" src="./img/paypal.png" alt="Name">
</p>

## Sponsor List

| Name | Sponsorship Amount | Contributed Files | Privileges |
|------|----------|---------|---------|
| [![Baitian Medical](./img/baitian.png)](https://baitianjituan.com) | ¬•5000 | 300 | Dedicated Technical Support |
| Knox User Anonymous Sponsorship | ¬•300 | 18 | Email/IM Service |
| [Bestming](https://www.mingagent.com) | ¬•100 | 6 | Email/IM Service |
| HJPING | ¬•100 | 6 | Email/IM Service |
| KingZ | ¬•50 | 2 | Email Service |
| JimLi | ¬•66 | 2 | Email Service |
| shanwu | ¬•50 | 2 | Email Service |
| xixi | ¬•50 | 2 | Email Service |

## Table of Contents

- [Architecture](#architecture)
- [Features](#features)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Configuration](#configuration)
- [Running the Server](#running-the-server)
- [API Compatibility](#api-compatibility)
- [Performance](#performance)
- [Development](#development)
- [Testing](#testing)
- [Deployment](#deployment)

## Architecture

### Technology Stack

- **Framework**: Actix-Web 4.x (one of the fastest web frameworks)
- **Runtime**: Tokio (async/await native runtime)
- **Database**: PostgreSQL with SQLx (compile-time checked queries)
- **Caching**: Redis with deadpool connection pooling
- **Authentication**: JWT with jsonwebtoken + Argon2/Bcrypt
- **Serialization**: Serde (zero-copy deserialization)
- **HTTP Client**: Reqwest (async HTTP/2 client)

### Project Structure

```
rust-backend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.rs              # Application entry point
‚îÇ   ‚îú‚îÄ‚îÄ config.rs            # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ db.rs                # Database connection pooling
‚îÇ   ‚îú‚îÄ‚îÄ error.rs             # Centralized error handling
‚îÇ   ‚îú‚îÄ‚îÄ models/              # Data models (25+ entities)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.rs          # User, session, API key models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.rs          # Chat, message models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model.rs         # AI model configurations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...              # Channel, file, knowledge, etc.
‚îÇ   ‚îú‚îÄ‚îÄ routes/              # HTTP route handlers (25+ modules)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.rs          # Authentication endpoints
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chats.rs         # Chat management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ openai.rs        # OpenAI-compatible API
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...              # Audio, images, tools, etc.
‚îÇ   ‚îú‚îÄ‚îÄ services/            # Business logic layer (27+ services)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chat.rs          # Chat processing service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.rs          # Authentication service
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag.rs           # RAG (Retrieval) service
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ...              # Model, user, file services
‚îÇ   ‚îú‚îÄ‚îÄ middleware/          # Request/response middleware
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.rs          # JWT authentication
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audit.rs         # Request auditing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rate_limit.rs    # Rate limiting
‚îÇ   ‚îú‚îÄ‚îÄ utils/               # Utility functions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ auth.rs          # JWT helpers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ embeddings.rs    # Vector embeddings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat_completion.rs # Chat utilities
‚îÇ   ‚îú‚îÄ‚îÄ socket.rs            # WebSocket/Socket.IO support
‚îÇ   ‚îî‚îÄ‚îÄ websocket_chat.rs    # Real-time chat streaming
‚îú‚îÄ‚îÄ migrations/              # Database migrations
‚îÇ   ‚îî‚îÄ‚îÄ postgres/            # PostgreSQL schema migrations
‚îú‚îÄ‚îÄ Cargo.toml               # Rust dependencies
‚îî‚îÄ‚îÄ .env.example             # Environment configuration template
```

## Features

### Implemented Features

#### Core Authentication & Authorization
- ‚úÖ JWT-based authentication with refresh tokens
- ‚úÖ API key authentication with endpoint restrictions
- ‚úÖ Role-based access control (Admin, User, Pending)
- ‚úÖ LDAP authentication support
- ‚úÖ OAuth 2.0/2.1 integration
- ‚úÖ SCIM 2.0 user provisioning
- ‚úÖ Session management with Redis

#### Chat & Messaging
- ‚úÖ OpenAI-compatible chat completions API
- ‚úÖ Real-time streaming with Server-Sent Events (SSE)
- ‚úÖ WebSocket-based chat streaming (zero-buffering)
- ‚úÖ Chat history management (CRUD operations)
- ‚úÖ Message editing and deletion
- ‚úÖ Chat tagging and organization
- ‚úÖ Multi-user chat sessions
- ‚úÖ Chat sharing and archiving

#### AI Model Management
- ‚úÖ Multi-provider model support (OpenAI, Ollama, etc.)
- ‚úÖ Model access control and permissions
- ‚úÖ Model caching for improved performance
- ‚úÖ Dynamic model loading and configuration
- ‚úÖ Model metadata and documentation
- ‚úÖ Arena model evaluation support

#### Knowledge & RAG (Retrieval-Augmented Generation)
- ‚úÖ Document upload and processing
- ‚úÖ Vector embeddings generation
- ‚úÖ Semantic search and retrieval
- ‚úÖ Hybrid search (vector + BM25)
- ‚úÖ Knowledge base management
- ‚úÖ File attachment support (10+ formats)
- ‚úÖ PDF extraction with image support
- ‚úÖ Web scraping and document loaders

#### Audio Processing
- ‚úÖ Speech-to-Text (STT) with Whisper, OpenAI, Azure
- ‚úÖ Text-to-Speech (TTS) with OpenAI, Azure, local models
- ‚úÖ Audio file upload and streaming
- ‚úÖ Multi-language support
- ‚úÖ Real-time audio transcription

#### Image Generation
- ‚úÖ OpenAI DALL-E integration
- ‚úÖ Stable Diffusion (Automatic1111) support
- ‚úÖ ComfyUI workflow integration
- ‚úÖ Google Gemini image generation
- ‚úÖ Image prompt enhancement
- ‚úÖ Image storage and retrieval

#### Advanced Features
- ‚úÖ Function/Tool calling support
- ‚úÖ Prompt management and templates
- ‚úÖ Memory system for contextual conversations
- ‚úÖ Task queue management with Redis
- ‚úÖ Background job processing
- ‚úÖ Webhook notifications
- ‚úÖ Rate limiting and throttling
- ‚úÖ Request auditing and logging
- ‚úÖ Health checks and monitoring
- ‚úÖ Graceful shutdown handling

#### Storage & Integration
- ‚úÖ Local file storage
- ‚úÖ S3-compatible storage (MinIO, AWS S3)
- ‚úÖ Google Drive integration
- ‚úÖ OneDrive integration
- ‚úÖ Multi-tenant file isolation

#### Developer Features
- ‚úÖ OpenAPI/Swagger documentation
- ‚úÖ Database migrations (automatic)
- ‚úÖ Environment-based configuration
- ‚úÖ Docker support with multi-stage builds
- ‚úÖ Comprehensive error messages
- ‚úÖ Request/response logging

### In Progress / Partial Implementation

- üîÑ MCP (Model Context Protocol) client
- üîÑ Advanced web search integrations
- üîÑ Code execution sandboxing
- üîÑ Jupyter notebook integration
- üîÑ Advanced RAG pipelines
- üîÑ LDAP group management

### Not Yet Implemented

- ‚ùå Some niche ML embeddings (Candle-based local inference)
- ‚ùå Certain specialized document loaders
- ‚ùå Some advanced Pipeline filters

> **Note**: The Rust backend implements approximately **85-90% of Python backend features**, with focus on the most commonly used functionality.

## Prerequisites

- **Rust**: 1.75+ (install via [rustup](https://rustup.rs/))
- **PostgreSQL**: 13+ (required)
- **Redis**: 6.0+ (optional, recommended for sessions and caching)
- **Operating System**: Linux, macOS, or Windows

## Installation

### 1. Clone Repository

```bash
cd rust-backend
```

### 2. Install Rust

```bash
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
```

### 3. Set Up Database

```bash
# Create PostgreSQL database
createdb openwebui

# Set database URL
export DATABASE_URL="postgresql://postgres:password@localhost:5432/openwebui"
```

### 4. Install Dependencies

```bash
# Dependencies are automatically managed by Cargo
cargo fetch
```

## Configuration

### Environment Variables

Create `.env` file in `rust-backend/` directory:

```bash
# Server Configuration
HOST=0.0.0.0
PORT=8080
ENV=production
RUST_LOG=info

# Security
WEBUI_SECRET_KEY=your-secret-key-min-32-chars
JWT_EXPIRES_IN=168h

# Database (Required)
DATABASE_URL=postgresql://user:pass@localhost:5432/openwebui

# Redis (Recommended)
ENABLE_REDIS=true
REDIS_URL=redis://localhost:6379

# Authentication
ENABLE_SIGNUP=true
ENABLE_LOGIN_FORM=true
ENABLE_API_KEY=true
DEFAULT_USER_ROLE=pending

# OpenAI Configuration (if using OpenAI models)
ENABLE_OPENAI_API=true
OPENAI_API_KEY=sk-your-key
OPENAI_API_BASE_URL=https://api.openai.com/v1

# CORS
CORS_ALLOW_ORIGIN=*

# Features
ENABLE_WEBSOCKET_SUPPORT=true
ENABLE_IMAGE_GENERATION=false
ENABLE_CODE_EXECUTION=false
ENABLE_WEB_SEARCH=false

# Audio (Optional)
TTS_ENGINE=openai
STT_ENGINE=openai

# RAG/Retrieval (Optional)
CHUNK_SIZE=1500
CHUNK_OVERLAP=100
RAG_TOP_K=5
```

See `.env.example` for complete configuration options.

### Configuration Precedence

1. Environment variables (highest priority)
2. `.env` file
3. Database-stored configuration
4. Default values (lowest priority)

## Running the Server

### Development Mode

```bash
cargo run
```

The server will start at `http://0.0.0.0:8080`

### Production Mode (Optimized)

```bash
cargo run --release
```

### Using the Build Script

```bash
./build.sh          # Builds release binary
./build.sh --dev    # Builds debug binary
./build.sh --run    # Builds and runs
```

### Docker

```bash
docker build -t open-webui-rust .
docker run -p 8080:8080 --env-file .env open-webui-rust
```

### Systemd Service (Linux)

```ini
[Unit]
Description=Open WebUI Rust Backend
After=network.target postgresql.service redis.service

[Service]
Type=simple
User=webui
WorkingDirectory=/opt/open-webui-rust
EnvironmentFile=/opt/open-webui-rust/.env
ExecStart=/opt/open-webui-rust/target/release/open-webui-rust
Restart=on-failure
RestartSec=5s

[Install]
WantedBy=multi-user.target
```

## API Compatibility

The Rust backend maintains **100% API compatibility** with the Python backend for core endpoints:

### Authentication
- `POST /api/v1/auths/signup` - User registration
- `POST /api/v1/auths/signin` - User login
- `POST /api/v1/auths/signout` - User logout
- `POST /api/v1/auths/api_key` - Generate API key

### Chat Completions
- `POST /api/chat/completions` - OpenAI-compatible chat
- `POST /api/v1/chat/completions` - Alternative endpoint
- `POST /openai/v1/chat/completions` - Full OpenAI compatibility
- `WS /api/ws/chat` - WebSocket streaming

### Models
- `GET /api/models` - List available models
- `GET /api/models/base` - List base models
- `POST /api/v1/models` - Create model
- `GET /api/v1/models/:id` - Get model details

### Users
- `GET /api/v1/users` - List users (admin)
- `GET /api/v1/users/:id` - Get user profile
- `PUT /api/v1/users/:id` - Update user
- `DELETE /api/v1/users/:id` - Delete user

### Files & Knowledge
- `POST /api/v1/files` - Upload file
- `GET /api/v1/files/:id` - Download file
- `POST /api/v1/knowledge` - Create knowledge base
- `GET /api/v1/retrieval/query` - Query knowledge

### Health & Status
- `GET /health` - Basic health check
- `GET /health/db` - Database connectivity check
- `GET /api/config` - Frontend configuration
- `GET /api/version` - Backend version

## Performance

### Quick Summary

| Metric | Python (FastAPI) | Rust (Actix-Web) | Improvement |
|--------|------------------|------------------|-------------|
| Login (p50) | 45ms | 3ms | **15x faster** |
| Chat Completion (p50) | 890ms | 35ms* | **25x faster** |
| Model List (p50) | 23ms | 1.2ms | **19x faster** |
| Memory (1000 req) | 450 MB | 85 MB | **5.3x lower** |
| Throughput | 850 req/s | 12,400 req/s | **14.6x higher** |

*Note: Chat completion speed primarily depends on LLM provider. Rust excels at streaming and handling overhead.

## Development

### Prerequisites

```bash
# Install development tools
rustup component add rustfmt clippy

# Install cargo-watch for auto-reload
cargo install cargo-watch
```

### Development Workflow

```bash
# Auto-reload on file changes
cargo watch -x run

# Run tests
cargo test

# Run tests with output
cargo test -- --nocapture

# Format code
cargo fmt

# Lint code
cargo clippy -- -D warnings

# Check without building
cargo check
```

### Code Structure Guidelines

1. **Models** (`src/models/`): Database entities with Serde serialization
2. **Services** (`src/services/`): Business logic, reusable across routes
3. **Routes** (`src/routes/`): HTTP handlers, thin layer calling services
4. **Middleware** (`src/middleware/`): Cross-cutting concerns (auth, logging)
5. **Utils** (`src/utils/`): Helper functions, no business logic

### Adding New Features

1. Add model in `src/models/[feature].rs`
2. Add database migration in `migrations/postgres/`
3. Implement service in `src/services/[feature].rs`
4. Add routes in `src/routes/[feature].rs`
5. Register routes in `src/routes/mod.rs`
6. Add tests

## Testing

### Unit Tests

```bash
cargo test --lib
```

### Integration Tests

```bash
# Set test database
export DATABASE_URL=postgresql://postgres:postgres@localhost:5432/openwebui_test

# Run integration tests
cargo test --test '*'
```

### Test with Demo Account

```bash
# The backend includes a demo account
# Email: test@test.com
# Password: test1234
```

### Load Testing

```bash
# Install wrk
brew install wrk  # macOS
sudo apt install wrk  # Ubuntu

# Run load test
wrk -t4 -c100 -d30s --latency http://localhost:8080/health
```

## Deployment

### Building for Production

```bash
# Build optimized binary
cargo build --release

# Binary location
./target/release/open-webui-rust

# Strip symbols (reduces size)
strip ./target/release/open-webui-rust
```

### Docker Deployment

```bash
# Multi-stage Docker build
docker build -t open-webui-rust:latest .

# Run with docker-compose
docker-compose up -d
```

### Performance Tuning

```toml
# Cargo.toml - Already optimized
[profile.release]
opt-level = 3           # Maximum optimization
lto = true              # Link-time optimization
codegen-units = 1       # Single codegen unit
strip = true            # Strip symbols
```

### Environment Variables for Production

```bash
# Use production settings
ENV=production
RUST_LOG=warn
ENABLE_REDIS=true

# Increase connection pools
DATABASE_POOL_SIZE=20
REDIS_MAX_CONNECTIONS=30

# Enable compression
ENABLE_COMPRESSION_MIDDLEWARE=true

# Set appropriate CORS
CORS_ALLOW_ORIGIN=https://yourdomain.com
```
